{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kmnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Abey12525/PYTHON_GEN/blob/master/Kmnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_DAHbOJj_8-9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyqEWTRQACQe",
        "colab_type": "code",
        "outputId": "bf1798c7-870d-4429-e7c9-39f0a4b99dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "#loading data \n",
        "data = tf.keras.datasets.mnist\n",
        "(train_x, train_y),(test_x,test_y) = data.load_data()\n",
        "enc = OneHotEncoder()\n",
        "print(\"test : {}\".format(test_y[0]))\n",
        "print(\"train : {}\".format(train_y[0]))\n",
        "test_y = test_y.reshape(-1,1)\n",
        "train_y = train_y.reshape(-1,1)\n",
        "enc.fit(train_y)\n",
        "train_y = enc.transform(train_y).toarray()\n",
        "enc.fit(test_y)\n",
        "test_y = enc.transform(test_y).toarray()\n",
        "print(\"test : {}\".format(test_y[0]))\n",
        "print(\"train : {}\".format(train_y[0]))\n",
        "print(\"shape = {}\".format(train_y.shape))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "test : 7\n",
            "train : 5\n",
            "test : [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "train : [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "shape = (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mzBsNoFTAj5G",
        "colab_type": "code",
        "outputId": "e1c8af11-c185-4468-d756-5811091f13b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#con = tf.nn.convolution(t,28,padding=\"same\")\n",
        "train_x = train_x.reshape(-1,28,28,1)\n",
        "test_x = test_x.reshape(-1,28,28,1)\n",
        "print(train_x.shape)\n",
        "print(test_x.shape)\n",
        "x = tf.placeholder(\"float\",[None,28,28,1])\n",
        "y = tf.placeholder(\"float\",[None,10])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C8mpE7TabLP9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Define the model"
      ]
    },
    {
      "metadata": {
        "id": "339Bi47kbQT9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x,w,b,strides = 1):\n",
        "    x = tf.nn.conv2d(x,w,strides=[1,strides,strides,1],padding = 'SAME')\n",
        "    x = tf.nn.bias_add(x,b)\n",
        "    return tf.nn.softmax(x)\n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    return tf.nn.max_pool(x,ksize=[1,k,k,1],strides=[1,k,k,1],padding = 'SAME')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wxn3xXunbU__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_classes = 10\n",
        "n_input = 28\n",
        "weights = {\n",
        "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'out': tf.get_variable('W4', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "}\n",
        "\n",
        "bias = {\n",
        "    'bc0':tf.get_variable('B0', shape=(32),initializer = tf.contrib.layers.xavier_initializer()),\n",
        "    'bc2':tf.get_variable('B1', shape=(64),initializer = tf.contrib.layers.xavier_initializer()),\n",
        "    'bc3':tf.get_variable('B2', shape=(128),initializer = tf.contrib.layers.xavier_initializer()),\n",
        "    'bd1':tf.get_variable('B3', shape=(128),initializer = tf.contrib.layers.xavier_initializer()),\n",
        "     'out':tf.get_variable('B4', shape=(10),initializer = tf.contrib.layers.xavier_initializer())\n",
        "}\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DmM-kMuabXUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mn_conv(x,weights,bias):\n",
        "    #first layer of convolution \n",
        "    conv1 = conv2d(x,weights['wc1'],bias['bc0'])\n",
        "    #pooling layer \n",
        "    pool1 = maxpool2d(conv1)\n",
        "    #second layer of convolution \n",
        "    conv2 = conv2d(pool1,weights['wc2'],bias['bc2'])\n",
        "    #pooling layer \n",
        "    pool2 = maxpool2d(conv2)\n",
        "    #third layer of conolution \n",
        "    conv3 = conv2d(pool2, weights['wc3'],bias['bc3'])\n",
        "    #pooling layer \n",
        "    pool3 = maxpool2d(conv3)\n",
        "    #flatining the output for dense layer input \n",
        "    den_inp = tf.reshape(pool3,[-1,weights['wd1'].get_shape().as_list()[0]])\n",
        "    #the y = wx + b output \n",
        "    y = tf.add(tf.matmul(den_inp,weights['wd1']),bias['bd1'])\n",
        "    #ReLU layer \n",
        "    rel = tf.nn.relu(y)\n",
        "    #output , class prediction , second dense layer \n",
        "    den_2_inp = tf.add(tf.matmul(y,weights['out']),bias['out'])\n",
        "    #return den_2_inp as output \n",
        "    return den_2_inp\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLZKBtCDbeme",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Define Loss function & Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "ZJbA_WEnbgYA",
        "colab_type": "code",
        "outputId": "ade86058-7c65-42a9-b161-3562c46419a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "training_iters = 10\n",
        "Lr_rate = 0.001\n",
        "batch_size = 128\n",
        "\n",
        "initilize = mn_conv(x,weights,bias)\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = initilize,labels = y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = Lr_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-c259de2ccb05>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ee9Eor5gbtZQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "metadata": {
        "id": "r-knrybgbwxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct_prediction = tf.equal(tf.argmax(initilize,1),tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmctmPZcbzLE",
        "colab_type": "code",
        "outputId": "b2421f27-7a26-4473-f00a-173170cbc245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "#init_op = tf.initialize_all_variables()\n",
        "bt_size = len(train_x)//batch_size\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
        "    print(\"Training.....\")\n",
        "    for i in range(training_iters):\n",
        "        for batch in range(bt_size):\n",
        "            batch_x = train_x[batch*batch_size:min((batch+1)*batch_size,len(train_x))]\n",
        "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]\n",
        "            opt = sess.run(optimizer, feed_dict = {x:batch_x, y:batch_y})\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict = {x:batch_x, y:batch_y})\n",
        "            if(batch%500==0):\n",
        "                print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
        "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                        \"{:.5f}\".format(acc))\n",
        "            test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_x,y : test_y})\n",
        "            train_loss.append(loss)\n",
        "            test_loss.append(valid_loss)\n",
        "            train_accuracy.append(acc)\n",
        "            test_accuracy.append(test_acc)\n",
        "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
        "    print(\"Model saved in path: %s\" % save_path)\n",
        "    print(\"Training Complete\")\n",
        "    summary_writer.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "Iter 0, Loss= 2.324465, Training Accuracy= 0.10156\n",
            "Iter 1, Loss= 0.089617, Training Accuracy= 0.97656\n",
            "Iter 2, Loss= 0.044525, Training Accuracy= 0.98438\n",
            "Iter 3, Loss= 0.031893, Training Accuracy= 0.98438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5thNhARgb2LU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}